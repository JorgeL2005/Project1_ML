# Proyecto 1 - Machine Learning

## ğŸ“Œ DescripciÃ³n
Este proyecto tiene como objetivo desarrollar un flujo de **Machine Learning** desde la carga y anÃ¡lisis de datos hasta la construcciÃ³n y evaluaciÃ³n de un modelo de regresiÃ³n.  
El trabajo se centra en aplicar conceptos fundamentales de **preprocesamiento**, **pipeline**, **visualizaciÃ³n** y **evaluaciÃ³n de mÃ©tricas**, siguiendo buenas prÃ¡cticas de estructuraciÃ³n de proyectos en Python.

---

## ğŸ“‚ Estructura del Proyecto
```bash
Proyecto1/
â”‚â”€â”€ data/               # Datos de entrada (crudos y procesados)
â”‚â”€â”€ notebooks/          # Notebooks exploratorios (EDA, pruebas)
â”‚â”€â”€ src/                # CÃ³digo fuente del proyecto
â”‚   â”œâ”€â”€ preprocessing.py # Limpieza y preparaciÃ³n de datos
â”‚   â”œâ”€â”€ modeling.py      # DefiniciÃ³n y entrenamiento de modelos
â”‚   â”œâ”€â”€ evaluation.py    # MÃ©tricas de evaluaciÃ³n
â”‚â”€â”€ reports/            # Resultados, grÃ¡ficas y anÃ¡lisis
â”‚â”€â”€ requirements.txt    # Dependencias del proyecto
â”‚â”€â”€ README.md           # DocumentaciÃ³n principal



---

## LibrerÃ­as Utilizadas

- **Procesamiento de datos**: `numpy`, `pandas`, `os`, `h5py`
- **ExtracciÃ³n de features de series temporales**: `tsfresh`
- **SelecciÃ³n de features**: `sklearn.feature_selection`
- **NormalizaciÃ³n de datos**: `sklearn.preprocessing.StandardScaler`
- **Balanceo de clases**: `imblearn.over_sampling.SMOTE`
- **VisualizaciÃ³n**: `matplotlib`, `seaborn`

---

## Flujo de Trabajo

### 1. Carga y ExploraciÃ³n de Datos
- Se cargan los datasets de entrenamiento y prueba desde archivos `.h5`.
- Se inspecciona la forma de los datos y se visualizan las primeras muestras.
- Se analiza la distribuciÃ³n de clases y se identifica desbalance entre `Control (0)` y `AlcohÃ³licos (1)`.

### 2. ConversiÃ³n de Series Temporales
- Los datos de EEG se convierten a formato â€œlongâ€ (`id`, `time`, `value`) compatible con `tsfresh`.
- Se crean `long_train_df` y `long_test_df` para extracciÃ³n de caracterÃ­sticas.

### 3. ExtracciÃ³n de Features
- Se extraen automÃ¡ticamente estadÃ­sticas de las series temporales usando `tsfresh`.
- Se procesan los datos en bloques para optimizar memoria y tiempo de cÃ³mputo.
- Se guarda cada bloque como CSV y se combinan en un dataset final.
- Se realiza selecciÃ³n de features relevantes usando `select_features` (basado en la variable objetivo).

### 4. SelecciÃ³n de Features y ReducciÃ³n de Dimensionalidad
- Se aplica **ANOVA F-test** para evaluar relevancia de cada feature con respecto a la clase.
- Se seleccionan las **top 20 features** mÃ¡s discriminativas.
- Se eliminan features redundantes basadas en anÃ¡lisis de correlaciÃ³n.

### 5. Balanceo de Clases
- Se aplica **SMOTE** para generar muestras sintÃ©ticas de la clase minoritaria.
- Se verifica la distribuciÃ³n equilibrada (50%-50%) de clases para entrenamiento.

### 6. Guardado de Datasets Finales
- `x_train_final.csv` y `x_test_final.csv` contienen las features depuradas y listas para el entrenamiento.
- `X_train_top20_features.csv` y `X_test_top20_features.csv` contienen Ãºnicamente las top 20 features seleccionadas.

---

## AnÃ¡lisis Exploratorio (EDA)

1. **DistribuciÃ³n de clases**:
   - La clase `Control` representa ~75% del dataset.
   - La clase `AlcohÃ³licos` representa ~25%.
   - Se recomienda balancear antes del entrenamiento.

2. **Matriz de correlaciÃ³n**:
   - Se visualiza la correlaciÃ³n entre features y con el target.
   - Se identifican features redundantes o altamente correlacionadas.

3. **VisualizaciÃ³n de features importantes**:
   - Se generan grÃ¡ficos de dispersiÃ³n entre las features mÃ¡s relevantes y la clase objetivo.
   - Esto permite identificar separaciÃ³n entre clases y posibles patrones discriminativos.

---

## CÃ³mo Ejecutar

1. Instalar dependencias:

```bash
pip install numpy pandas h5py tsfresh scikit-learn imbalanced-learn matplotlib seaborn

2. Ejecutar el notebook de preprocesamiento y EDA:

```bash
jupyter notebook notebooks/EDA_Preprocessing.ipynb


3. Los datasets finales (x_train_final.csv y x_test_final.csv) estarÃ¡n listos para entrenar modelos de machine learning como SVM, Random Forest, XGBoost, etc.


## Notas Importantes

- Los datos de EEG tienen 18,530 registros por sujeto.
- La extracciÃ³n de features se realiza sobre el primer canal de EEG, aunque puede extenderse a todos los canales.
- Mantener nombres y orden de features consistentes entre entrenamiento y prueba.