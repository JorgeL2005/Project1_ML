{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb8cac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.feature_extraction import MinimalFCParameters\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebabe678",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"train.h5\"\n",
    "test_file = \"test.h5\"\n",
    "\n",
    "with h5py.File(train_file, \"r\") as f:\n",
    "    X_train = f[\"x\"][:]   # se침ales EEG\n",
    "    y_train = f[\"y\"][:]   # etiquetas\n",
    "\n",
    "with h5py.File(test_file, \"r\") as f:\n",
    "    X_test = f[\"x\"][:]    # se침ales EEG\n",
    "\n",
    "# Exploraci칩n r치pida\n",
    "print(X_train.shape, X_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(X_train[0,0,:5])  # primeras 5 muestras de EEG del primer sujeto\n",
    "print(y_train[:5])       # primeras 5 etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcc00f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a DataFrame ancho\n",
    "x_h5_train_df = pd.DataFrame(X_train[:,0,:])\n",
    "y_h5_train_df = pd.Series(y_train)\n",
    "\n",
    "def parsear_times_series(dataset):\n",
    "    parsed_data = []\n",
    "    for id, series in enumerate(dataset):\n",
    "        time_series_df = pd.DataFrame({\n",
    "            'id': id,\n",
    "            'time': np.arange(len(series)),\n",
    "            'value': series\n",
    "        })\n",
    "        parsed_data.append(time_series_df)\n",
    "    return pd.concat(parsed_data)\n",
    "\n",
    "# Parsear train y test (primer canal [:,0,:])\n",
    "long_train_df = parsear_times_series(X_train[:,0,:])\n",
    "long_test_df = parsear_times_series(X_test[:,0,:])\n",
    "\n",
    "y_train_series = pd.Series(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d9f8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_en_bloques(long_df, y_labels=None, bloque_size=5, dataset_name=\"train\"):\n",
    "    os.makedirs(\"features_chunks\", exist_ok=True)\n",
    "    n_ids = long_df['id'].nunique()\n",
    "    chunks_files = []\n",
    "\n",
    "    fc_parameters = MinimalFCParameters()  # features r치pidas\n",
    "\n",
    "    for start in range(0, n_ids, bloque_size):\n",
    "        end = min(start + bloque_size, n_ids)\n",
    "        bloque_ids = list(range(start, end))\n",
    "        bloque_df = long_df[long_df['id'].isin(bloque_ids)]\n",
    "\n",
    "        # Extraer features\n",
    "        features_bloque = extract_features(\n",
    "            bloque_df,\n",
    "            column_id='id',\n",
    "            column_sort='time',\n",
    "            default_fc_parameters=fc_parameters\n",
    "        )\n",
    "        impute(features_bloque)\n",
    "        # Guardar CSV temporal\n",
    "        file_path = f\"features_chunks/{dataset_name}_features_{start}_{end}.csv\"\n",
    "        features_bloque.to_csv(file_path)\n",
    "        chunks_files.append(file_path)\n",
    "        print(f\"Bloque {start}-{end} procesado y guardado en {file_path}\")\n",
    "\n",
    "    # Combinar todos los CSVs\n",
    "    features_final = pd.concat([pd.read_csv(f, index_col=0) for f in chunks_files])\n",
    "\n",
    "    # Selecci칩n de features si hay etiquetas\n",
    "    if y_labels is not None:\n",
    "        features_final = select_features(features_final, y_labels)\n",
    "\n",
    "    # 游댳 Guardar el archivo combinado\n",
    "    final_file = f\"features_chunks/{dataset_name}_features_final.csv\"\n",
    "    features_final.to_csv(final_file)\n",
    "    print(f\"Features combinadas guardadas en {final_file}\")\n",
    "\n",
    "    return features_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23258d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features = procesar_en_bloques(long_train_df, y_labels=y_train_series, bloque_size=20, dataset_name=\"train\")\n",
    "X_test_features = procesar_en_bloques(long_test_df, y_labels=None, bloque_size=20, dataset_name=\"test\")\n",
    "\n",
    "# Alinear columnas (usar solo columnas de train en test)\n",
    "X_test_features = X_test_features[X_train_features.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78d07c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LogisticRegression': (\n",
    "        LogisticRegression(max_iter=1000, solver='liblinear'),\n",
    "        {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2']}\n",
    "    ),\n",
    "    'SVM': (\n",
    "        SVC(),\n",
    "        {'C': [0.1, 1, 10], 'kernel': ['linear','rbf']}\n",
    "    )\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "for name, (model, params) in models.items():\n",
    "    grid = GridSearchCV(model, params, cv=5, scoring='f1', n_jobs=-1)\n",
    "    grid.fit(X_train_features, y_train_series)\n",
    "    best_models[name] = grid.best_estimator_\n",
    "    print(f\"Mejor modelo {name}: {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05fb3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test_features)  # test no tiene etiquetas reales\n",
    "    print(f\"\\nPredicciones {name}:\")\n",
    "    print(y_pred[:20])  # mostrar primeras 20 predicciones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
